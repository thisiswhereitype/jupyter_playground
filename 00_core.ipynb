{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Core\n",
    "> Reusable utils for download caching and pipelining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp core\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "from nbdev.showdoc import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "import dataclasses\n",
    "import sys\n",
    "from typing import Any, Callable, Union, List\n",
    "\n",
    "\n",
    "import joblib\n",
    "import joblib.memory\n",
    "import requests as rq\n",
    "from fastcore.all import *\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class DownloadContent:\n",
    "    \"\"\"\n",
    "    Masks the repr with it's hash to avoid serialising the content.\n",
    "    This stops libraries like joblib serialising large strings in input reprs\n",
    "    \"\"\"\n",
    "\n",
    "    content: bytes\n",
    "\n",
    "    def __repr__(self):\n",
    "        return joblib.hash(self.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exporti\n",
    "\n",
    "\n",
    "class Standin:\n",
    "    def cache(self, func):\n",
    "        return func\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "if __name__ != \"__main__\":\n",
    "    if sys.platform == \"linux\":\n",
    "        cache = joblib.Memory(\n",
    "            \"/mnt/d/.joblib\", verbose=0, compress=True, bytes_limit=int(200e9)\n",
    "        )\n",
    "    if sys.platform == \"win32\":\n",
    "        cache = joblib.Memory(\n",
    "            \"D:\\.joblib\", verbose=0, compress=True, bytes_limit=int(200e9)\n",
    "        )\n",
    "    cache.reduce_size()\n",
    "else:\n",
    "    if in_jupyter():\n",
    "        cache = joblib.Memory(verbose=1, compress=True)\n",
    "    else:\n",
    "        cache = Standin()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exports\n",
    "\n",
    "\n",
    "@cache.cache\n",
    "def attachment_download(href):\n",
    "    res = rq.get(href)\n",
    "    res.raise_for_status()\n",
    "    return DownloadContent(res.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class IncrementalPipeline:\n",
    "    \"\"\"\n",
    "    A class whose instances can dynamically store functions.\n",
    "    When used as a callable passes each stages retunred object as args into each successive function.\n",
    "    Results are wrapped if needed.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, name: str, funcs: List[Callable] = None) -> None:\n",
    "        self._name = name\n",
    "        self._funcs = L(funcs)\n",
    "        self._fuse_cache = None\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"{IncrementalPipeline.__name__}(name='{self._name}', _funcs={[f.__name__  for f in self._funcs]})\"\n",
    "\n",
    "    def decorate_func(self, func):\n",
    "        self.append_func(func)\n",
    "        return func\n",
    "\n",
    "    def append_func(self, *funcs: List[Callable]):\n",
    "        self._funcs += funcs\n",
    "        return self\n",
    "\n",
    "    def __getitem__(self, idx: Union[int, slice, Iterable]):\n",
    "        return IncrementalPipeline(self._name, self._funcs[idx])\n",
    "\n",
    "    def __call__(\n",
    "        self,\n",
    "        *args: list[Any],\n",
    "        tqdm_position: int = 0,\n",
    "        **init_kwargs: dict[Any, Any],\n",
    "    ):\n",
    "        try:\n",
    "            for i, f in tqdm(\n",
    "                enumerate(self._funcs), leave=None, position=tqdm_position\n",
    "            ):\n",
    "                if not i:\n",
    "                    res = f(*args, **init_kwargs)\n",
    "                else:\n",
    "                    res = f(*res)\n",
    "                res = res if is_listy(res) else (res,)\n",
    "        except (ValueError, TypeError) as e:\n",
    "            raise ValueError(f'{i}: When calling \"{f}\", args: {args}') from e\n",
    "\n",
    "        if isinstance(res, (tuple, fastuple)):\n",
    "            # unwrap redundant tuple\n",
    "            return res if res.__len__() > 1 else res[0]\n",
    "        else:\n",
    "            return res\n",
    "\n",
    "    @delegates(tqdm)\n",
    "    def run_group(\n",
    "        self,\n",
    "        job_args: Iterable[Tuple[Any]],\n",
    "        init_kwargs: Dict[str, Any] = None,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        with tqdm(enumerate(job_args), **{**dict(desc=\"Jobs\"), **kwargs}) as ti:\n",
    "            for _, arg in ti:\n",
    "                yield self(\n",
    "                    *arg,\n",
    "                    **{\n",
    "                        **dict(\n",
    "                            init_kwargs=dict() if init_kwargs is None else init_kwargs,\n",
    "                            tqdm_position=1,\n",
    "                        ),\n",
    "                        **kwargs,\n",
    "                    },\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IncrementalPipeline(name='Eg 1', _funcs=[])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = IncrementalPipeline(\"Eg 1\")\n",
    "\n",
    "p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IncrementalPipeline(name='Eg 2', _funcs=['add_one', 'add_one'])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = IncrementalPipeline(\"Eg 2\")\n",
    "\n",
    "\n",
    "@p.decorate_func\n",
    "def add_one(a, **_):\n",
    "    return a + 1\n",
    "\n",
    "\n",
    "p.append_func(add_one)\n",
    "p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:00, 14563.56it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Jobs: 10it [00:00, 79.99it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((#10) [0,1,2,3,4,5,6,7,8,9], (#10) [1,2,3,4,5,6,7,8,9,10])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L(range(10)), L(p[:1].run_group(L(range(10)).map(fastuple)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "import nbdev\n",
    "\n",
    "nbdev.nbdev_export()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyplay",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "d63662cd386c7c9018ef920bde7115f93fea20e76e65dad276fae97b3d678c79"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
